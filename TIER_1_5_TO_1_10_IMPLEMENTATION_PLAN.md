# TIER 1.5-1.10 Implementation Plan
## Security Hardening (40 hours total)
**Status**: Ready to Start | **Priority Sequence**: 1.10 → 1.5 → 1.7 → 1.6 → 1.9 → 1.8

---

## Recommended Implementation Order (by impact vs. effort)

### Phase 1: Quick Wins (12 hours) – Do These First
- [ ] **1.10 Anonymization Salt** (2 hrs) - Zero dependencies, fast fix
- [ ] **1.7 Access Control** (4 hrs) - Single endpoint fix, high security impact
- [ ] **1.5 Session Management** (6 hrs) - Core auth hardening, foundational

### Phase 2: Infrastructure (16 hours)
- [ ] **1.9 Database Pooling** (6 hrs) - Affects all DB operations
- [ ] **1.6 Error Handling** (10 hrs) - Systematic cleanup, prevents debug leakage

### Phase 3: Frontend (12 hours)
- [ ] **1.8 XSS Prevention** (12 hrs) - Largest, but isolated to frontend

---

## ITEM 1.10: Anonymization Salt (2 hours) ⚡ START HERE
**File**: `training_data_manager.py`  
**Risk**: Hardcoded salt undermines anonymization security  
**Status**: Not started

### What's Wrong
```python
# Current (WRONG):
ANONYMIZATION_SALT = "default_salt_12345"  # Hardcoded!
```
Anyone with the source code can reverse the anonymization.

### What to Implement
1. **Generate random salt on first app startup** (if not exists)
2. **Store in environment variable** (not source code)
3. **Document salt rotation procedure**

### Implementation Steps

#### Step 1: Update `.env.example`
Add this variable:
```bash
# ANONYMIZATION SALT (auto-generated on first run if not set)
ANONYMIZATION_SALT=<auto-generated-on-startup>
```

#### Step 2: Modify `training_data_manager.py` (top of file)
Find the hardcoded salt and replace with:
```python
import os
import secrets

# Generate random anonymization salt on startup if not set
def get_anonymization_salt():
    """Get or generate anonymization salt from environment"""
    salt = os.getenv('ANONYMIZATION_SALT')
    if not salt:
        # Generate 32-byte random salt (64 hex chars)
        salt = secrets.token_hex(32)
        print(f"⚠️  ANONYMIZATION_SALT not set. Generated random salt.")
        print(f"Set environment variable: export ANONYMIZATION_SALT={salt}")
        if not os.getenv('DEBUG'):
            # In production, fail-closed if salt not explicitly set
            raise RuntimeError(
                "ANONYMIZATION_SALT must be set in production. "
                "Set via environment variable or Railway dashboard."
            )
    return salt

ANONYMIZATION_SALT = get_anonymization_salt()
```

#### Step 3: Update all uses of `ANONYMIZATION_SALT`
Replace `ANONYMIZATION_SALT` with `get_anonymization_salt()` or store result at module load.

### Testing
```bash
# Test 1: Development mode (auto-generates)
DEBUG=1 python3 -c "from training_data_manager import get_anonymization_salt; print(get_anonymization_salt())"

# Test 2: Production mode (should fail without env var)
DEBUG=0 python3 -c "from training_data_manager import get_anonymization_salt; print(get_anonymization_salt())" 
# Should raise RuntimeError ✅

# Test 3: With env var set
ANONYMIZATION_SALT="test123..." python3 -c "from training_data_manager import get_anonymization_salt; print(get_anonymization_salt())"
# Should return "test123..." ✅
```

### Verification Checklist
- [ ] Salt is never hardcoded in source
- [ ] Salt is read from environment variable
- [ ] Random salt generated on first run (DEBUG mode only)
- [ ] Production fails without explicit ANONYMIZATION_SALT
- [ ] All uses updated to call `get_anonymization_salt()`
- [ ] .env.example updated
- [ ] Tests pass: `pytest tests/ -v`
- [ ] Git commit with message: `security(1.10): remove hardcoded anonymization salt`

**Time**: 1-2 hours  
**Next**: Move to 1.7 Access Control

---

## ITEM 1.7: Access Control - Professional Endpoints (4 hours)
**File**: `api.py` lines 10189-10221  
**Risk**: `/api/professional/ai-summary` takes `clinician_username` from request body (forgeable)  
**Status**: Not started

### What's Wrong
```python
# VULNERABLE:
@app.route('/api/professional/ai-summary', methods=['POST'])
def ai_summary():
    clinician_username = request.json.get('clinician_username')  # ❌ FORGEABLE!
    # Any user can impersonate any clinician
```

### What to Implement
Always derive professional identity from **session**, NEVER request body.

### Implementation Steps

#### Step 1: Find all "professional" endpoints
```bash
grep -n "professional\|clinician" api.py | grep "@app.route"
```

#### Step 2: For each endpoint, apply pattern:
```python
# CORRECT:
@app.route('/api/professional/ai-summary', methods=['POST'])
def ai_summary():
    # 1. Get clinician from session (only source of truth)
    username = session.get('username')
    if not username:
        return jsonify({'error': 'Authentication required'}), 401
    
    # 2. Check clinician role (if needed)
    conn = get_db_connection()
    cur = get_wrapped_cursor(conn)
    cur.execute('SELECT role FROM users WHERE username=%s', (username,))
    user = cur.fetchone()
    if not user or user['role'] not in ['clinician', 'admin']:
        return jsonify({'error': 'Clinician access required'}), 403
    
    # 3. Now use clinician_username = username (never from request)
    try:
        # ... rest of logic
        log_event(username, 'professional', 'ai_summary_generated', '')
        return jsonify({'summary': summary}), 200
    except Exception as e:
        return jsonify({'error': 'Operation failed'}), 500
    finally:
        conn.close()
```

#### Step 3: Search for all instances where identity is taken from request body
```bash
grep -n "request.json.get.*username\|request.json.get.*patient\|request.args.get.*username" api.py
```
Each one needs review and likely replacement.

### Verification Checklist
- [ ] All professional endpoints use `session.get('username')`
- [ ] Request body `clinician_username` or `patient_username` never trusted
- [ ] Role checks in place for clinician-only endpoints
- [ ] All endpoints log access: `log_event(username, 'professional', action, details)`
- [ ] Tests verify identity spoofing is blocked
- [ ] Tests pass: `pytest tests/ -v`
- [ ] Git commit: `security(1.7): fix access control - clinician identity from session only`

**Time**: 3-5 hours  
**Next**: Move to 1.5 Session Management

---

## ITEM 1.5: Session Management Hardening (6 hours)
**File**: `api.py` lines 147-165  
**Risk**: 30-day session (too long), no rotation on login, no inactivity timeout, no invalidation on password change  
**Status**: Not started

### What's Wrong
```python
# CURRENT (WEAK):
app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(days=30)  # Too long!
# Missing: session rotation, inactivity timeout, password change invalidation
```

### What to Implement

#### Change 1: Reduce Session Lifetime (30 days → 7 days)
Find line ~165 and change:
```python
app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(days=7)  # Reduced from 30
```

#### Change 2: Add Session Rotation on Login
Find login endpoint and add session ID rotation:
```python
@app.route('/api/auth/login', methods=['POST'])
def login():
    # ... existing auth logic ...
    
    # AFTER successful password verification:
    session.clear()  # Clear old session
    session['username'] = username
    session['login_time'] = datetime.utcnow().isoformat()
    session['last_activity'] = datetime.utcnow().isoformat()
    session.permanent = True
    
    log_event(username, 'auth', 'login_successful', '')
    return jsonify({'success': True, 'csrf_token': csrf_token}), 200
```

#### Change 3: Add Inactivity Timeout (30 minutes)
Add middleware before_request:
```python
from datetime import datetime, timedelta

@app.before_request
def check_session_timeout():
    """Invalidate session after 30 minutes of inactivity"""
    if 'username' in session:
        last_activity = session.get('last_activity')
        if last_activity:
            last_activity_time = datetime.fromisoformat(last_activity)
            if datetime.utcnow() - last_activity_time > timedelta(minutes=30):
                session.clear()
                return jsonify({'error': 'Session expired due to inactivity'}), 401
        
        # Update last activity timestamp
        session['last_activity'] = datetime.utcnow().isoformat()
```

#### Change 4: Invalidate Sessions on Password Change
Find password change endpoint and add:
```python
@app.route('/api/auth/change-password', methods=['POST'])
def change_password():
    # ... existing password change logic ...
    
    # AFTER successful password update:
    cur.execute('UPDATE users SET password_hash=%s WHERE username=%s', (new_hash, username))
    conn.commit()
    
    # Invalidate all sessions for this user (force re-login)
    cur.execute('DELETE FROM sessions WHERE username=%s', (username,))
    conn.commit()
    
    # Clear current session
    session.clear()
    
    log_event(username, 'auth', 'password_changed_sessions_invalidated', '')
    return jsonify({'success': True, 'message': 'Password changed. Please log in again.'}), 200
```

### Verification Checklist
- [ ] Session lifetime is 7 days (not 30)
- [ ] Session clears on login (rotation)
- [ ] Last activity timestamp tracked
- [ ] Sessions expire after 30 min inactivity
- [ ] Sessions invalidated on password change
- [ ] Session invalidation on logout (if not already)
- [ ] Tests verify timeout and rotation work
- [ ] Tests pass: `pytest tests/ -v`
- [ ] Git commit: `security(1.5): session hardening - timeout, rotation, invalidation`

**Time**: 5-7 hours  
**Next**: Move to 1.9 Database Pooling

---

## ITEM 1.9: Database Connection Pooling (6 hours)
**File**: `api.py` throughout (100+ `get_db_connection()` calls)  
**Risk**: Connection exhaustion under load; no connection reuse  
**Status**: Not started

### What's Wrong
```python
# CURRENT (INEFFICIENT):
conn = get_db_connection()  # Creates new connection every time
# ...
conn.close()
# When 100 users request simultaneously, 100 new connections created = exhaustion
```

### What to Implement
Use PostgreSQL connection pooling (psycopg2.pool).

#### Step 1: Create Connection Pool Helper (top of api.py)
```python
from psycopg2 import pool
import threading

# Create thread-safe connection pool (max 20 connections)
_db_pool = None
_db_pool_lock = threading.Lock()

def get_db_pool():
    """Get or create thread-safe database connection pool"""
    global _db_pool
    if _db_pool is None:
        with _db_pool_lock:
            if _db_pool is None:
                _db_pool = pool.ThreadedConnectionPool(
                    minconn=2,      # Minimum 2 connections always ready
                    maxconn=20,     # Maximum 20 connections
                    host=os.getenv('DB_HOST', 'localhost'),
                    port=int(os.getenv('DB_PORT', 5432)),
                    database=os.getenv('DB_NAME', 'healing_space'),
                    user=os.getenv('DB_USER', 'postgres'),
                    password=os.getenv('DB_PASSWORD'),
                    connect_timeout=30
                )
    return _db_pool

def get_db_connection_pooled():
    """Get connection from pool (more efficient than creating new)"""
    pool = get_db_pool()
    conn = pool.getconn()
    return conn

def return_db_connection(conn):
    """Return connection to pool for reuse"""
    pool = get_db_pool()
    pool.putconn(conn)
```

#### Step 2: Replace `get_db_connection()` with context manager pattern
Instead of:
```python
conn = get_db_connection()
try:
    # ... logic ...
finally:
    conn.close()
```

Use:
```python
@contextmanager
def get_db_connection_from_pool():
    """Context manager for connection pooling"""
    conn = get_db_connection_pooled()
    try:
        yield conn
    finally:
        return_db_connection(conn)

# Usage:
with get_db_connection_from_pool() as conn:
    cur = get_wrapped_cursor(conn)
    cur.execute('SELECT * FROM users WHERE username=%s', (username,))
    # connection automatically returned to pool on exit
```

#### Step 3: Gradually replace all `get_db_connection()` calls
Search and replace pattern (do this systematically):
```python
# Find: conn = get_db_connection()
# Replace with: with get_db_connection_from_pool() as conn:
# And indent the following code
```

### Verification Checklist
- [ ] Connection pool created at module load
- [ ] Pool has min=2, max=20 connections
- [ ] Context manager pattern implemented
- [ ] All `get_db_connection()` calls migrated (can be gradual)
- [ ] Connections returned to pool after use
- [ ] Load test: verify no connection exhaustion with 100 concurrent users
- [ ] Tests pass: `pytest tests/ -v`
- [ ] Git commit: `infrastructure(1.9): add database connection pooling`

**Time**: 5-7 hours (can be done iteratively)  
**Next**: Move to 1.6 Error Handling

---

## ITEM 1.6: Error Handling & Debug Cleanup (10 hours)
**File**: `api.py` and supporting modules (100+ `except Exception: pass`)  
**Risk**: Silent failures hide bugs; debug prints expose sensitive data  
**Status**: Not started

### What's Wrong
```python
# CURRENT (DANGEROUS):
try:
    do_something_important()
except Exception:
    pass  # ❌ Silently ignores errors, hard to debug

print(f"User {username} accessing {endpoint}")  # ❌ Leaks usernames to logs
```

### What to Implement

#### Step 1: Set up Python Logging Module (top of api.py)
```python
import logging
import logging.handlers

# Configure structured logging
logging.basicConfig(
    level=logging.INFO if not os.getenv('DEBUG') else logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # Console output
        logging.handlers.RotatingFileHandler(
            'healing_space.log',
            maxBytes=10485760,  # 10MB
            backupCount=10
        )
    ]
)

app_logger = logging.getLogger(__name__)
```

#### Step 2: Find all bare `except Exception` and replace
```bash
grep -n "except Exception" api.py
```

For each match, replace with specific exception and logging:
```python
# WRONG:
try:
    cur.execute(sql)
except Exception:
    pass

# CORRECT:
try:
    cur.execute(sql)
except psycopg2.Error as e:
    app_logger.error(f"Database error in operation: {e}", exc_info=True)
    return jsonify({'error': 'Database operation failed'}), 500
except Exception as e:
    app_logger.error(f"Unexpected error: {e}", exc_info=True)
    return jsonify({'error': 'Internal server error'}), 500
```

#### Step 3: Remove debug print statements
```bash
grep -n "^[[:space:]]*print(" api.py
```

Replace with logging:
```python
# WRONG:
print(f"User {username} logged in")

# CORRECT:
app_logger.info(f"User authenticated via session")
```

#### Step 4: Audit sensitive logging
Never log:
- ❌ Passwords or password hashes
- ❌ API keys
- ❌ Usernames in error messages (use user IDs)
- ❌ Full request/response bodies with sensitive data

Safe to log:
- ✅ Action category (auth, therapy, clinical)
- ✅ Outcome (success/failure)
- ✅ Error type (not full traceback in user-facing response)
- ✅ Timestamps
- ✅ Audit trail details

### Verification Checklist
- [ ] Logging module configured
- [ ] All bare `except Exception` replaced with specific types
- [ ] All exceptions logged with `exc_info=True` for debugging
- [ ] No debug print statements remain
- [ ] No sensitive data in logs (passwords, API keys, usernames)
- [ ] Error responses don't leak internal details
- [ ] Tests verify error handling works
- [ ] Tests pass: `pytest tests/ -v`
- [ ] Git commit: `quality(1.6): error handling and debug cleanup`

**Time**: 8-12 hours (systematic audit required)  
**Next**: Move to 1.8 XSS Prevention

---

## ITEM 1.8: XSS Prevention - innerHTML Audit (12 hours)
**File**: `templates/index.html` (138+ innerHTML instances)  
**Risk**: User-generated content (posts, messages, pet names, plans) rendered unsanitized  
**Status**: Not started

### What's Wrong
```javascript
// VULNERABLE:
document.getElementById('pet-name').innerHTML = petName;  // User can inject <script>
```

### What to Implement

#### Step 1: Find all innerHTML uses
```bash
grep -n "\.innerHTML\s*=" templates/index.html | wc -l
# Should show ~138
```

#### Step 2: Categorize each innerHTML
For each, ask: "Is this user-generated data?"
- **User data** (pet names, post content, mood notes) → Use `textContent` or DOMPurify
- **Pre-rendered HTML** (UI templates, markdown) → Keep `innerHTML` but validate source

#### Step 3: Add DOMPurify to HTML head
```html
<!-- In templates/index.html <head> -->
<script src="https://cdn.jsdelivr.net/npm/dompurify@3.0.6/dist/purify.min.js"></script>
```

#### Step 4: Replace user data innerHTML with textContent
```javascript
// VULNERABLE:
document.getElementById('post-content').innerHTML = userPost;

// SAFE:
document.getElementById('post-content').textContent = userPost;
```

#### Step 5: For rich content (markdown, HTML), use DOMPurify
```javascript
// If you need to render user-provided markdown/HTML:
const cleanHTML = DOMPurify.sanitize(userContent);
document.getElementById('rich-content').innerHTML = cleanHTML;
```

#### Step 6: Create sanitization helper function
```javascript
// In static/js/main.js
function safeSetHTML(elementId, htmlContent) {
    /**
     * Safely set HTML content with DOMPurify sanitization
     * @param {string} elementId - Element to update
     * @param {string} htmlContent - HTML content to sanitize
     */
    const cleanHTML = DOMPurify.sanitize(htmlContent, {
        ALLOWED_TAGS: ['b', 'i', 'em', 'strong', 'a', 'br', 'p', 'ul', 'li'],
        ALLOWED_ATTR: ['href', 'target']
    });
    document.getElementById(elementId).innerHTML = cleanHTML;
}

function safeSetText(elementId, textContent) {
    /**
     * Set text content (safe for all user data)
     * @param {string} elementId - Element to update
     * @param {string} textContent - Text content
     */
    document.getElementById(elementId).textContent = textContent;
}
```

### Verification Checklist
- [ ] All 138 innerHTML instances reviewed
- [ ] User-generated data uses `textContent` (not `innerHTML`)
- [ ] Rich content uses DOMPurify sanitization
- [ ] DOMPurify configured with minimal allowed tags
- [ ] No script tags allowed in DOMPurify config
- [ ] No event handlers allowed in HTML (no `onclick="..."`)
- [ ] Tests verify XSS attempts are blocked
- [ ] Tests pass: `pytest tests/ -v`
- [ ] Git commit: `security(1.8): prevent XSS via innerHTML sanitization`

**Time**: 10-14 hours (tedious but straightforward)

---

## IMPLEMENTATION CHECKLIST (Track Your Progress)

```
PHASE 1: Quick Wins (12 hours)
- [ ] 1.10 Anonymization Salt (2 hrs) - DONE: commit sha_______
- [ ] 1.7 Access Control (4 hrs) - DONE: commit sha_______
- [ ] 1.5 Session Management (6 hrs) - DONE: commit sha_______

PHASE 2: Infrastructure (16 hours)
- [ ] 1.9 Database Pooling (6 hrs) - DONE: commit sha_______
- [ ] 1.6 Error Handling (10 hrs) - DONE: commit sha_______

PHASE 3: Frontend (12 hours)
- [ ] 1.8 XSS Prevention (12 hrs) - DONE: commit sha_______

TOTAL: 40 hours
All tests passing: [ ]
All items committed: [ ]
Ready for TIER 1.1 (Dashboard): [ ]
```

---

## Per-Item Git Workflow

For each item, use this workflow:
```bash
# 1. Create feature branch
git checkout -b security/tier1-item-number

# 2. Make changes, test locally
pytest tests/ -v

# 3. Verify syntax
python3 -m py_compile api.py cbt_tools/*.py training_data_manager.py

# 4. Commit with clear message
git commit -m "security(1.N): brief description of change"

# 5. Push and verify tests pass
git push origin security/tier1-item-number
```

Then merge to main once tests confirmed passing on Railway.

---

**Ready to start? Begin with 1.10 (Anonymization Salt) - it's the quickest win!**
